{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building your own layer\n",
    "\n",
    "Based on [this keras page](https://keras.io/layers/writing-your-own-keras-layers/)\n",
    "\n",
    "```\n",
    "For simple, stateless custom operations, you are probably better off using layers.core.Lambda layers. But for any custom operation that has trainable weights, you should implement your own layer.\n",
    "```\n",
    "\n",
    "Here is the skeleton of a Keras layer, as of Keras 2.0 (if you have an older version, please upgrade). There are only three methods you need to implement:\n",
    "\n",
    "- `build(input_shape)`: Called when the model containing the layer is built. This is where you will define your weights. \n",
    "- `call(x)`: this is where the layer's logic lives. Unless you want your layer to support masking, you only have to care about the first argument passed to call: the input tensor.\n",
    "- `compute_output_shape(input_shape)`: in case your layer modifies the shape of its input, you should specify here the shape transformation logic. This allows Keras to do automatic shape inference.\n",
    "\n",
    "\n",
    "Let's create a Dense network which uses ReLu by default as activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmperez/.pyenv/versions/3.6.5/envs/ml/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/jmperez/.pyenv/versions/3.6.5/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "\n",
    "class ReLuLayer(Layer):\n",
    "\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        super(ReLuLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Create a trainable weight variable for this layer.\n",
    "        self.kernel = self.add_weight(name='kernel', \n",
    "                                      shape=(input_shape[1], self.output_dim),\n",
    "                                      initializer='uniform',\n",
    "                                      trainable=True)\n",
    "        super(ReLuLayer, self).build(input_shape)  # Be sure to call this at the end\n",
    "\n",
    "    def call(self, x):\n",
    "        prod = K.dot(x, self.kernel)\n",
    "        return K.relu(prod)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8ae333e9b0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "X_train = X_train[..., np.newaxis]\n",
    "X_test = X_test[..., np.newaxis]\n",
    "\n",
    "plt.imshow(np.squeeze(X_train[10]), cmap=plt.cm.gray_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 10), (10000, 10))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "y_train = to_categorical(y_train)\n",
    "\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPool2D\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(10, kernel_size=(3, 3), input_shape=X_train[0].shape, activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(ReLuLayer(64))\n",
    "#model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile('adam', loss='categorical_crossentropy', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 54000 samples, validate on 6000 samples\n",
      "Epoch 1/5\n",
      "54000/54000 [==============================] - 9s 158us/step - loss: 11.0900 - acc: 0.3070 - val_loss: 8.7557 - val_acc: 0.4430\n",
      "Epoch 2/5\n",
      "54000/54000 [==============================] - 8s 155us/step - loss: 1.9457 - acc: 0.7669 - val_loss: 0.3878 - val_acc: 0.8627\n",
      "Epoch 3/5\n",
      "54000/54000 [==============================] - 9s 158us/step - loss: 0.3329 - acc: 0.8800 - val_loss: 0.3547 - val_acc: 0.8738\n",
      "Epoch 4/5\n",
      "54000/54000 [==============================] - 9s 160us/step - loss: 0.2819 - acc: 0.8946 - val_loss: 0.3387 - val_acc: 0.8785\n",
      "Epoch 5/5\n",
      "54000/54000 [==============================] - 9s 163us/step - loss: 0.2482 - acc: 0.9072 - val_loss: 0.3490 - val_acc: 0.8812\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8ae330f390>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

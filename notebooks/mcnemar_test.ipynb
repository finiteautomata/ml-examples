{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of Classifiers \n",
    "\n",
    "In this notebook, we use the `statsmodels'` implementation of `McNemar` test. This statistical tool serves to assess whether two classifiers perform \"equally\" well over a test set.\n",
    "\n",
    "First, let's load the Breast Cancer Dataset. We will construct two RandomForest with 50 and 51 estimators with the hope that there is no real difference in their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.datasets import load_iris, load_breast_cancer, load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = load_breast_cancer()\n",
    "\n",
    "data = dataset.data\n",
    "target = dataset.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into train and test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the classifiers and print their accuracy scores over the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jmperez/.pyenv/versions/3.6.5/envs/ml/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest with 50 estimators: 0.9649122807017544\n",
      "Accuracy of Random Forest with 51 estimators: 0.956140350877193\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data, target, test_size=0.2)\n",
    "\n",
    "clf_A = RandomForestClassifier(n_estimators=50)\n",
    "clf_B = RandomForestClassifier(n_estimators=51)\n",
    "\n",
    "clf_A.fit(X_train, Y_train)\n",
    "clf_B.fit(X_train, Y_train)\n",
    "\n",
    "print(\"Accuracy of Random Forest with 50 estimators: {}\".format(clf_A.score(X_test, Y_test)))\n",
    "print(\"Accuracy of Random Forest with 51 estimators: {}\".format(clf_B.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference here is not huge, so we expect that the McNemar test doesn't reject the null hypothesis of the two classifiers performing equally well (i.e. having the same error rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-Value : 0.25\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.sandbox.stats.runs import mcnemar\n",
    "\n",
    "stats, pval = mcnemar(clf_A.predict(X_test), clf_B.predict(X_test), exact=True)\n",
    "\n",
    "print(\"P-Value : {}\".format(pval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value is well enough above 0.05, so we don't reject $H_0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing for different classifiers\n",
    "\n",
    "In this case, we expect to see a difference between a RandomForest and a Naive Bayes classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Random Forest: 0.9824561403508771\n",
      "Accuracy of Naive Bayes: 0.6403508771929824\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data, target, test_size=0.2)\n",
    "\n",
    "clf_A = RandomForestClassifier(n_estimators=50)\n",
    "clf_B = BernoulliNB()\n",
    "\n",
    "clf_A.fit(X_train, Y_train);\n",
    "clf_B.fit(X_train, Y_train);\n",
    "\n",
    "print(\"Accuracy of Random Forest: {}\".format(clf_A.score(X_test, Y_test)))\n",
    "print(\"Accuracy of Naive Bayes: {}\".format(clf_B.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-Value : 2.2737367544323206e-13\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.sandbox.stats.runs import mcnemar\n",
    "\n",
    "stats, pval = mcnemar(clf_A.predict(X_test), clf_B.predict(X_test), exact=True)\n",
    "\n",
    "print(\"P-Value : {}\".format(pval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the p-value shows that there is evidence of the two classifiers not performing identically. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
